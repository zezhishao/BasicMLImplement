{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 什么是KNN\n",
    "\n",
    "KNN全称为k-NearestNeighbor。机器学习中有许多K-whatever，经常为人称道的K-means及其各种变种。这些算法里的K都是代表的一个超参数\"K\"。\n",
    "\n",
    "K近邻算法是一类最基本的分类和回归方法。分类问题用的最多。\n",
    "\n",
    "### 2. KNN的基本思想\n",
    "\n",
    "对于给定的数据集：\n",
    "$$T=\\{(x_1,y_1),(x_2,y_2),\\dots,(x_N,y_N)\\}$$\n",
    "对于给定的输入向量$x$，KNN模型计算这个点最近的k各点。然后根据某一种决策规则（一般为投票决策）判定输入$x$所属的类别。当k=1的时候，\n",
    "\n",
    "显然，KNN有一下几个特点：\n",
    "1. 不存在显式的训练过程。\n",
    "2. 需要自己定义距离度量。\n",
    "3. k值的选择。\n",
    "4. 分类决策规则的确定。\n",
    "\n",
    "### 3. 定义距离度量函数\n",
    "#### a. $L_p$距离\n",
    "$$\n",
    "\\begin{equation}\n",
    "L_p(x_i,x_j)=(\\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|)^{\\frac{1}{p}}\n",
    ",\\qquad p\\geq1\n",
    "\\end{equation}\n",
    "$$\n",
    "$p = 2$的时候，称为欧式距离；$p=1$称为曼哈顿距离；$p=\\infty$，它是各个坐标距离的最大值。\n",
    "\n",
    "#### b. Minkowski距离\n",
    "\n",
    "### 4. k值的选择\n",
    "k比较小的时候，近似误差减小，估计误差增大。但是会对邻近的实例点非常敏感，如果邻近点是噪声点，就会出错。也就是模型过于复杂，产生了“过拟合”。\n",
    "\n",
    "k值比较大的时候，减少学习的估计误差，但是近似误差会增大。用较大的邻域中的训练实例进行预测，较远的实例点也会起作用，从而使得预测发生错误。k值增大意味着模型变得简单。\n",
    "\n",
    "例如当K增大到数据量N，那么无论输入的实力是什么，豆浆简单的预测这个训练集中较多的类。这时候，模型过于简单，完全忽略了训练实例中的大量有用信息。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 5. 分类决策规则\n",
    "\n",
    "分类决策规则往往是多数镖局。\n",
    "\n",
    "在多数表决的前提下，误分率就是：\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i\\neq c_j)=1-\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i= c_j)\n",
    "\\end{equation}\n",
    "$$\n",
    "要想是的误分率最小即经验风险最小，就要是的$\\sum_{x_i\\in N_k(x)}I(y_i= c_j)$最大，所以大多数表决规则等价于经验风险最小化。\n",
    "\n",
    "### 6. 其他的一些知识\n",
    "1. 经验风险最小化和结构风险最小化\n",
    "\n",
    ">$Y$是真实标签，$f(X)$是模型输出。记损失函数为$L(Y,f(x))$，对于整个数据集来说，损失函数的期望是\n",
    "$$R_{exp}(f)=E[L(Y,f(x)]$$\n",
    "学习的目标，其实就是要选择期望风险最小的模型。对于给定的数据集：\n",
    "$$T=\\{(x_1,y_1),(x_2,y_2),\\dots,(x_N,y_N)\\}$$\n",
    "模型$f(X)$关于训练数据集的平均损失称为经验风险活经验损失：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "R_{exp}(f)=\\frac{1}{N}\\sum_{t=1}^N L(y_i,f(x_i)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    ">根据大数定理，数据集数量足够大的时候，经验风险最小化能保证有很好的学习效果。但是样本容量很小时，经验风险往往会产生过拟合的现象。结构风险最小化就是防止过拟合的策略。它在经验风险上加入了表示模型复杂度的正则化项（或者叫惩罚项）：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "R_{exp}(f)=\\frac{1}{N}\\sum_{t=1}^N L(y_i,f(x_i) + \\lambda J(f)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "其中$J(f)$是定义在假设空间$F$上的返汉，模型$f$越复杂，复杂度$J(f)$越大。\n",
    "\n",
    "\n",
    "2. 近似误差和估计误差\n",
    "> 近似误差：可以理解为对现有训练集的训练误差。 \n",
    "估计误差：可以理解为对测试集的测试误差。\n",
    "\n",
    "3. k近邻需要借助搜索算法实现快速的搜索计算过程，例如kd树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def L(x, y, p=2):\n",
    "    # x1 = [1, 1], x2 = [5,1]\n",
    "    if len(x) == len(y) and len(x) > 1:\n",
    "        sum = 0\n",
    "        for i in range(len(x)):\n",
    "            sum += math.pow(abs(x[i] - y[i]), p)\n",
    "        return math.pow(sum, 1 / p)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 课本例题3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1, 1]\n",
    "x2 = [5, 1]\n",
    "x3 = [4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, '1-[5, 1]')\n",
      "(4.0, '1-[5, 1]')\n",
      "(3.7797631496846193, '1-[4, 4]')\n",
      "(3.5676213450081633, '1-[4, 4]')\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    r = {'1-{}'.format(c): L(x1, c, p=i) for c in [x2, x3]}\n",
    "    print(min(zip(r.values(), r.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
