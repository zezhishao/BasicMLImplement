## 什么是评估方法

评估方法是指，从一个包含$m$个样例的数据集$D={(x_1, y_1), (x_2, y_2),\dots (x_m, y_m)}$的数据集中，通过适当的处理，从中产生出训练集$S$和测试集$T$。产生的训练集和测试机用于训练、测试模型的能力，并给出评估结果。


## 留出（Hand-out）验证法

直接从数据集$D$中划分出两个不相交的数据集。分别作为训练和测试集。这两个数据集的分布要一致，这样才有普遍性。且分布要与原数据集也保持一致。

一般采用若干次随机划分、重复进行实验评估后取平均值作为留出法的结果。

## 交叉验证

交叉验证更多被称为$k$折交叉验证。这种验证方法先把数据集$D$划分为$k$个不相交的子集，当然每个子集的分布也要尽可能一致。然后在这$k$个不相交的子集中，选取一个作为测试，另外的$k-1$个作为训练。这样可以得到$k$组训练/测试集。最终返回的结果是这$k$次测试的平均值。常用的$k$值有是10，其他的还有5，20等。

当然交叉验证也可以想留出法一样，采用若干次交叉验证，然后取平均。假如取了$p$次10折交叉验证结果的均值，就可以成为$p$次10折交叉验证。

**10次10折交叉验证法**和**100次留出法**都是进行了100次训练/测试。


## K折交叉验证的特例——留一验证

当$K=m$时，就得到了K折交叉验证的一个特例，留一法。留一法每次都只拿出1个样本做验证，其他的样本作为训练集。直至每个样本都曾经做过验证集。

留一法很不常用。
因为数据集比较大的时候，例如有$m$个数据，根据留一法，就要训练$m$个模型。这是万万不能忍受的。

当然留一法还有自己的优势，那就是训练集只和整个数据集差一个样本，所以可以最大限度的利用数据。

当然了，留一法的估计结果未必永远比其他的评估方法更准确，**没有免费的午餐定理依旧适用**。
