{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»€ä¹ˆæ˜¯é›†æˆå­¦ä¹ \n",
    "\n",
    "é›†æˆå­¦ä¹ æ˜¯ä¸€ç±»æå‡æ–¹æ³•ã€‚**â€œå›¢ç»“å°±æ˜¯åŠ›é‡â€**å°±æ˜¯ä»–çš„å®—æ—¨ã€‚\n",
    "\n",
    "**é€šè¿‡ç»“åˆå¤šä¸ªæ¨¡å‹ï¼Œå¯ä»¥äº§ç”Ÿä¸€ä¸ªæ›´å¼ºå¤§çš„æ¨¡å‹ã€‚**æ˜¯ä»–çš„åŸºæœ¬æŒ‡å¯¼æ€æƒ³ã€‚\n",
    "\n",
    "é›†æˆå­¦ä¹ æ˜¯åœ¨Kaggleæˆ–è€…å¤©æ± ç­‰æ¯”èµ›ä¸­ï¼Œæƒ³è¦è¾¾åˆ°æœ€é«˜åæ¬¡æ—¶ï¼Œå‡ ä¹å¿…ç”¨çš„æ‰‹æ®µã€‚æœ€æœ´ç´ çš„æƒ³æ³•æ˜¯æŠ•ç¥¨votingã€‚Votingæ˜¯æœ€æœ´ç´ çš„æ–¹æ³•ã€‚é‰´äºè¿‡äºç®€å•æœ´ç´ ï¼Œæ•ˆæœæå‡æœ‰é™ï¼Œç”¨å¾—å¾ˆå°‘ã€‚\n",
    "\n",
    "é›†æˆå­¦ä¹ ä¸»è¦åŒ…æ‹¬ä¸‰å¤§æ–¹æ³•ï¼š\n",
    "- Bagging\n",
    "- Boosting\n",
    "- Stacking\n",
    "\n",
    "ğŸŒ°ï¼š\n",
    "Baggingï¼šéšæœºæ£®æ—\n",
    "Boostingï¼šAdaboost\n",
    "Stackingï¼šStackingçš„æ–¹æ³•æ›´åŠ çµæ´»ï¼Œå¯ä»¥è‡ªå®šä¹‰å±‚æ•°ã€æ•°æ®é‡é‡‡æ ·æ–¹æ³•ã€‚\n",
    "\n",
    "### é›†æˆå­¦ä¹ çš„ç‰¹ç‚¹\n",
    "\n",
    "é›†æˆå­¦ä¹ çš„ç‰¹ç‚¹æ˜¯**ä½¿ç”¨å¤šä¸ªæ¨¡å‹**ï¼Œä¸ä¹‹ç›¸ä¼´çš„å¦ä¸€ä¸ªç‰¹ç‚¹æ˜¯**å¯¹æ•°æ®é›†çš„å„ç§ä½¿ç”¨æ–¹æ³•**ã€‚\n",
    "\n",
    "### è®¾è®¡ä¸€ä¸ªé›†æˆå­¦ä¹ æ¨¡å‹æ—¶éœ€è¦å…³æ³¨çš„é—®é¢˜ï¼š\n",
    "\n",
    "1. å¦‚ä½•è®¾è®¡å¼±å­¦ä¹ å™¨\n",
    "\n",
    "> é€šå¸¸è¿™äº›å­¦ä¹ å™¨çš„å½¢å¼æ˜¯ä¸€è‡´çš„\n",
    "\n",
    "2. å¦‚ä½•æŠŠè¿™äº›å¼±å­¦ä¹ å™¨ç»“åˆåœ¨ä¸€èµ·\n",
    "\n",
    "> ç»“åˆå¤šä¸ªå­¦ä¹ å™¨çš„ç®—æ³•æˆä¸ºMeta-Algorithmsï¼Œè¿™ä¸ªç®—æ³•ä¸ºäº†äº§ç”Ÿæ›´å¥½çš„æ•ˆæœï¼Œè°ƒç”¨å…¶ä»–ç®—æ³•ï¼ˆè‹¥åˆ†ç±»å™¨ï¼‰ä½œä¸ºè¾“å…¥ã€‚\n",
    "\n",
    "> what is meta-algorithmsï¼š\n",
    "Loosely speaking, a meta-algorithm is an algorithm that wraps and executes other algorithms and might feed them input data or use their output data. A common goal is to achieve a better task performance compared to the performance of each of those algorithms on their own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "\n",
    "### 1. Bagging\n",
    "\n",
    "#### 1.1 Booststrap\n",
    "\n",
    "Baggingçš„å…¨ç§°æ˜¯â€œ**B**ootstrap **AGG**regat**ING**â€ã€‚\n",
    "\n",
    "Booststrapæ˜¯ä¸€ä¸ªé‡é‡‡æ ·æ–¹æ³•ï¼šé€šè¿‡ä»åŸå§‹çš„$N$ä¸ªæ ·æœ¬æ•°æ®$D=\\{x_1,x_2,\\dots,x_N\\}$ï¼Œè¿›è¡Œ$N$æ¬¡æœ‰æ”¾å›é‡‡æ ·$N$ä¸ªæ•°æ® ï¼Œç§°ä¸ºä¸€ä¸ªbootstrapæ ·æœ¬ã€‚\n",
    "Booststrapé€šè¿‡**æœ‰æ”¾å›çš„é‡‡æ ·**ï¼Œå¾—åˆ°å’ŒåŸæ¥çš„æ•°æ®é›†å¤§å°ä¸å˜çš„æ–°æ•°æ®é›†ï¼Œå…¶ä¸­å‡ ä¹å¿…ç„¶ä¼šæœ‰é‡å¤ï¼Œæ‰€ä»¥è¿™ä¸ªæ“ä½œç­‰ä»·äºç»™æ ·æœ¬reweightingã€‚\n",
    "\n",
    "#### 1.2 Baggingçš„ç®—æ³•è¿‡ç¨‹\n",
    "\n",
    "è®¾åŸºå­¦ä¹ å™¨çš„ä¸ªæ•°ä¸º$M$ä¸ªï¼Œé‚£ä¹ˆå°±ä»æ•°æ®é›†ä¸­è¿›è¡Œ$M$æ¬¡Booststrapã€‚ç”¨è¿™$M$ä¸ªæ•°æ®é›†è®­ç»ƒå¯ä»¥å¾—åˆ°$M$ä¸ªæ¨¡å‹ã€‚\n",
    "å¯¹è¿™$M$ä¸ªæ¨¡å‹æŒ‰å¦‚ä¸‹æ–¹å¼æŠ•ç¥¨:\n",
    "$$f_{avg}(x)=\\frac{1}{N}\\sum_{m=1}^Mf_m(x)$$\n",
    "\n",
    "**å¯ä»¥è¯æ˜ï¼šBaggingå¯ä»¥é™ä½æ¨¡å‹çš„æ–¹å·®ã€‚**\n",
    "\n",
    "#### 1.3 Baggingå…·æœ‰é™ä½æ¨¡å‹æ–¹å·®çš„åŠŸæ•ˆ\n",
    "\n",
    "å¯¹äºMä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹ä¼šäº§ç”Ÿä¸€ä¸ªâ€œæ ·æœ¬â€Xï¼Œè¿™äº›æ ·æœ¬éƒ½æ˜¯ä»ä¸€ä¸ªå‡å€¼ä¸º$\\mu$ï¼Œæ–¹å·®ä¸º$\\sigma$çš„åˆ†å¸ƒä¸­äº§ç”Ÿçš„ã€‚\n",
    "\n",
    "è¿™äº›æ ·æœ¬çš„å‡å€¼ä¸º$\\hat{X}$å¯ä»¥çœ‹æˆå¦ä¸€ä¸ªæ–°çš„æ ·æœ¬ï¼Œè¯¥æ ·æœ¬æœä»å‡å€¼ä¸º$\\mu$ã€æ–¹å·®ä¸º$\\frac{\\sigma^2}{M}$çš„åˆ†å¸ƒï¼ˆé€šè¿‡ç®€å•çš„æ¦‚ç‡å…¬å¼å°±å¯ä»¥æ¨å¯¼å‡ºæ¥ï¼‰ã€‚\n",
    "\n",
    "ç”±æ­¤ï¼Œå¯ä»¥å¯¹Baggingåšå‡ºä¸¤ä¸ªç»“è®ºï¼š\n",
    "1. æ ·æœ¬å‡å€¼$\\hat{X}$çš„æœŸæœ›å’Œ$X$çš„æœŸæœ›ç›¸ç­‰ï¼ˆæ— åä¼°è®¡ï¼‰\n",
    "2. æ ·æœ¬å‡å€¼$\\hat{X}$çš„æ–¹å·®æ¯”$X$çš„æ–¹å·®å°ï¼Œä¸”æ ·æœ¬æ•°ï¼ˆæ¨¡å‹æ•°é‡ï¼‰è¶Šå¤§ï¼Œæ–¹å·®å°±è¶Šå°ã€‚\n",
    "\n",
    "å› æ­¤Baggingå¯ä»¥é™ä½æ¨¡å‹æ–¹å·®ï¼Œä¸”ä¸æ”¹å˜æ¨¡å‹åå·®ã€‚å› æ­¤Baggingé€‚ç”¨äºåå·®ä½ã€æ–¹å·®é«˜çš„æ¨¡å‹ã€‚ä¾‹å¦‚å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œã€‚å†³ç­–æ ‘+Baggingå°±æ˜¯éšæœºæ£®æ—äº†ã€‚å¦å¤–åœ¨sklearnä¸­æ”¯æŒå¯¹ä»»æ„çš„åŸºå­¦ä¹ å™¨çš„Baggingã€‚\n",
    ">- åˆ†ç±»ï¼šBaggingClassifier\n",
    ">- å›å½’ï¼šBaggingRegressor\n",
    "\n",
    "Baggingçš„æ¯ä¸ªåŸºå­¦ä¹ å™¨åªåœ¨åŸå§‹æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ä¸Šè®­ç»ƒï¼Œæ‰€ä»¥å¯ä»¥ä¸ç”¨äº¤å‰éªŒè¯ï¼Œç›´æ¥ç”¨åŒ…å¤–æ ·æœ¬ä¸Šçš„è¯¯å·® ï¼ˆout-of-bag errorï¼‰æ¥ä¼°è®¡å®ƒçš„æ³›åŒ–è¯¯å·®/æµ‹è¯•è¯¯å·®ã€‚\n",
    "<img src=\"./images/Bagging.png\" alt=\"SVM \" style=\"zoom:28%;\" />\n",
    "\n",
    "\n",
    "å¦å¤–ï¼Œä»¥ä¸Šè®¡ç®—æ˜¯åœ¨å„ä¸ªæ¨¡å‹ä¹‹é—´ç›¸äº’ç‹¬ç«‹çš„æƒ…å†µä¸‹è¿›è¡Œçš„ã€‚ä½†æ˜¯çœŸå®æƒ…å†µä¸‹å¹¶ä¸ç‹¬ç«‹ï¼Œå› ä¸ºä»–ä»¬ä¼šå…¬ç”¨è®¸å¤šçš„æ•°æ®ã€‚æ‰€ä»¥é™ä½æ–¹å·®çš„æ€§èƒ½ä¼šå¤§æ‰“æŠ˜æ‰£ã€‚å…¶æŠ˜æ‰£åŠ›åº¦æ˜¯è¿™ä¹ˆè®¡ç®—çš„ï¼šå‡è®¾$f_m(x)$ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯$\\rho$ï¼Œåˆ™$f_{avg}(x)$çš„æ–¹å·®ä¸º$\\rho x \\sigma^2 + (1-\\rho)x\\frac{\\sigma^2}{M}$\n",
    "\n",
    "\n",
    "è¿˜æœ‰ä¸€ç‚¹ï¼Œå‚æ•°åŸºå­¦ä¹ å™¨æ•°ç›®n_estimatorsä¸æ˜¯æ¨¡å‹å¤æ‚åº¦å‚æ•°ï¼Œæ— éœ€é€šè¿‡äº¤å‰éªŒè¯æ¥ç¡®å®šã€‚å‚æ•°å€¼å»ºè®®ï¼š\n",
    "\n",
    "- å¯¹åˆ†ç±»é—®é¢˜ï¼Œå¯è®¾ç½®åŸºå­¦ä¹ å™¨æ•°ç›®ä¸º$\\sqrt{D}$ï¼Œ å…¶ä¸­$D$ä¸ºç‰¹å¾æ•°ç›®ï¼›\n",
    "\n",
    "- å¯¹å›å½’é—®é¢˜ï¼Œå¯è®¾ç½®åŸºå­¦ä¹ å™¨æ•°ç›®ä¸º$\\frac{D}{3}$ã€‚\n",
    "\n",
    "#### 1.4 éšæœºæ£®æ—\n",
    "\n",
    "ç”±äºä»…è®­ç»ƒæ•°æ®æœ‰äº›ä¸åŒï¼Œå¯¹å†³ç­–æ ‘ç®—æ³•è¿›è¡ŒBaggingå¾—åˆ°çš„å¤šæ£µæ ‘é«˜åº¦ç›¸å…³ï¼Œå› æ­¤å¸¦æ¥çš„æ–¹å·®å‡å°‘æœ‰é™ã€‚\n",
    "\n",
    "éšæœºæ£®æ—é€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªæ–¹æ³•æ¥é™ä½æ ‘ä¹‹é—´çš„ç›¸å…³æ€§ï¼š\n",
    "\n",
    "â€¢ éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†ç‰¹å¾\n",
    "\n",
    "â€¢ éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬\n",
    "\n",
    "\n",
    "éšæœºæ£®æ—åœ¨å¾ˆå¤šåº”ç”¨æ¡ˆä¾‹è¢«è¯æ˜æœ‰æ•ˆï¼Œä½†ç‰ºç‰²äº†å¯è§£é‡Šæ€§\n",
    "\n",
    "â€¢ æ£®æ—ï¼šå¤šæ£µæ ‘\n",
    "\n",
    "â€¢ éšæœºï¼šå¯¹æ ·æœ¬å’Œç‰¹å¾è¿›è¡ŒéšæœºæŠ½å–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Boosting\n",
    "\n",
    "å­¦ä¹ ä¸€ä¸ªå¼ºåˆ†ç±»å™¨å¾ˆéš¾ï¼Œä½†æ˜¯å­¦ä¹ ä¸€ä¸ªè‹¥åˆ†ç±»å™¨å¾ˆç®€å•ã€‚é€šè¿‡å­¦ä¹ **ä¸€ç³»åˆ—**çš„å¼±åˆ†ç±»å™¨ï¼Œä»–ä»¬ç›¸äº’ç»“åˆè¾¾åˆ°å¼ºåˆ†ç±»å™¨çš„æ•ˆæœã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåˆ†ç±»å™¨çš„å­¦ä¹ æ˜¯æœ‰é¡ºåºçš„ã€‚\n",
    "\n",
    "ä¾‹å¦‚å…ˆå­¦ä¹ ä¸€ä¸ªå¼±åˆ†ç±»å™¨$\\phi_1$ï¼Œå†å­¦ä¹ ç¬¬äºŒä¸ªå¼±åˆ†ç±»å™¨$\\phi_2$ã€‚ç¬¬äºŒä¸ªåˆ†ç±»å™¨å¸®åŠ©ç¬¬ä¸€ä¸ªåˆ†ç±»å™¨ï¼ˆå’Œç¬¬ä¸€ä¸ªåˆ†ç±»å™¨äº’è¡¥ï¼‰ã€‚ç„¶åå†è®­ç»ƒç¬¬ä¸‰ä¸ªå¼±åˆ†ç±»å™¨...ä¸€ç›´è¿™ä¹ˆè®­ç»ƒä¸‹å»ã€‚\n",
    "\n",
    "æœ€åç»„åˆæ‰€æœ‰Mä¸ªå¼±åˆ†ç±»å™¨ï¼š\n",
    "$$f(x) = \\sum_{m=1}^M\\alpha_m\\phi_m(x)$$\n",
    "\n",
    "æœ‰å„ç§å„æ ·çš„Boostingï¼Œä¾‹å¦‚Adaboostã€FilterBoostã€GentleBoostã€GradientBoostã€MadaBoostã€LogitBoostã€LPBoostç­‰ç­‰ã€‚ä»–ä»¬çš„ä¸åŒç‚¹å°±æ˜¯åœ¨äº**å¦‚ä½•è®¾è®¡å¼±åˆ†ç±»å™¨**å’Œ**å¦‚ä½•æŠŠå¼±åˆ†ç±»å™¨ç»“åˆèµ·æ¥**è¿™ä¸¤ç‚¹ä¸Šã€‚\n",
    "\n",
    "\n",
    "#### 2.1 Adaboost\n",
    "AdaBoostæ˜¯AdaptiveBoostçš„ç¼©å†™ï¼Œè¡¨æ˜è¯¥ç®—æ³•æ˜¯å…·æœ‰é€‚åº”æ€§çš„æå‡ç®—æ³•ã€‚\n",
    "\n",
    "ç®—æ³•çš„æ­¥éª¤å¦‚ä¸‹ï¼š\n",
    "\n",
    "1ï¼‰ç»™æ¯ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆ$x_{1},x_{2},â€¦.,x_{N}$ï¼‰åˆ†é…æƒé‡ï¼Œåˆå§‹æƒé‡$w_{1}$å‡ä¸º1/Nã€‚\n",
    "\n",
    "2ï¼‰é’ˆå¯¹å¸¦æœ‰æƒå€¼çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œå¾—åˆ°æ¨¡å‹$G_m$ï¼ˆåˆå§‹æ¨¡å‹ä¸ºG1ï¼‰ã€‚\n",
    "\n",
    "3ï¼‰è®¡ç®—æ¨¡å‹$G_m$çš„è¯¯åˆ†ç‡$e_m=\\sum_{i=1}^Nw_iI(y_i\\not= G_m(x_i))$\n",
    "\n",
    "4ï¼‰è®¡ç®—æ¨¡å‹$G_m$çš„ç³»æ•°$\\alpha_m=0.5\\log[(1-e_m)/e_m]$\n",
    "\n",
    "5ï¼‰æ ¹æ®è¯¯åˆ†ç‡eå’Œå½“å‰æƒé‡å‘é‡$w_m$æ›´æ–°æƒé‡å‘é‡$w_{m+1}$ã€‚\n",
    "\n",
    "6ï¼‰è®¡ç®—ç»„åˆæ¨¡å‹$f(x)=\\sum_{m=1}^M\\alpha_mG_m(x_i)$çš„è¯¯åˆ†ç‡ã€‚\n",
    "\n",
    "7ï¼‰å½“ç»„åˆæ¨¡å‹çš„è¯¯åˆ†ç‡æˆ–è¿­ä»£æ¬¡æ•°ä½äºä¸€å®šé˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£ï¼›å¦åˆ™ï¼Œå›åˆ°æ­¥éª¤2ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äº§ç”Ÿæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a213ab8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0):\n",
    "        self.clf_num = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_args(self, datasets, labels):\n",
    "\n",
    "        self.X = datasets\n",
    "        self.Y = labels\n",
    "        self.M, self.N = datasets.shape\n",
    "\n",
    "        # å¼±åˆ†ç±»å™¨æ•°ç›®å’Œé›†åˆ\n",
    "        self.clf_sets = []\n",
    "\n",
    "        # åˆå§‹åŒ–weights\n",
    "        self.weights = [1.0 / self.M] * self.M\n",
    "\n",
    "        # G(x)ç³»æ•° alpha\n",
    "        self.alpha = []\n",
    "\n",
    "    def _G(self, features, labels, weights):\n",
    "        m = len(features)\n",
    "        error = 100000.0  # æ— ç©·å¤§\n",
    "        best_v = 0.0\n",
    "        # å•ç»´features\n",
    "        features_min = min(features)\n",
    "        features_max = max(features)\n",
    "        n_step = (features_max - features_min +\n",
    "                  self.learning_rate) // self.learning_rate\n",
    "        # print('n_step:{}'.format(n_step))\n",
    "        direct, compare_array = None, None\n",
    "        for i in range(1, int(n_step)):\n",
    "            v = features_min + self.learning_rate * i\n",
    "\n",
    "            if v not in features:\n",
    "                # è¯¯åˆ†ç±»è®¡ç®—\n",
    "                compare_array_positive = np.array(\n",
    "                    [1 if features[k] > v else -1 for k in range(m)])\n",
    "                weight_error_positive = sum([\n",
    "                    weights[k] for k in range(m)\n",
    "                    if compare_array_positive[k] != labels[k]\n",
    "                ])\n",
    "\n",
    "                compare_array_nagetive = np.array(\n",
    "                    [-1 if features[k] > v else 1 for k in range(m)])\n",
    "                weight_error_nagetive = sum([\n",
    "                    weights[k] for k in range(m)\n",
    "                    if compare_array_nagetive[k] != labels[k]\n",
    "                ])\n",
    "\n",
    "                if weight_error_positive < weight_error_nagetive:\n",
    "                    weight_error = weight_error_positive\n",
    "                    _compare_array = compare_array_positive\n",
    "                    direct = 'positive'\n",
    "                else:\n",
    "                    weight_error = weight_error_nagetive\n",
    "                    _compare_array = compare_array_nagetive\n",
    "                    direct = 'nagetive'\n",
    "\n",
    "                # print('v:{} error:{}'.format(v, weight_error))\n",
    "                if weight_error < error:\n",
    "                    error = weight_error\n",
    "                    compare_array = _compare_array\n",
    "                    best_v = v\n",
    "        return best_v, direct, error, compare_array\n",
    "\n",
    "    # è®¡ç®—alpha\n",
    "    def _alpha(self, error):\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "    # è§„èŒƒåŒ–å› å­\n",
    "    def _Z(self, weights, a, clf):\n",
    "        return sum([\n",
    "            weights[i] * np.exp(-1 * a * self.Y[i] * clf[i])\n",
    "            for i in range(self.M)\n",
    "        ])\n",
    "\n",
    "    # æƒå€¼æ›´æ–°\n",
    "    def _w(self, a, clf, Z):\n",
    "        for i in range(self.M):\n",
    "            self.weights[i] = self.weights[i] * np.exp(\n",
    "                -1 * a * self.Y[i] * clf[i]) / Z\n",
    "\n",
    "    # G(x)çš„çº¿æ€§ç»„åˆ\n",
    "    def _f(self, alpha, clf_sets):\n",
    "        pass\n",
    "\n",
    "    def G(self, x, v, direct):\n",
    "        if direct == 'positive':\n",
    "            return 1 if x > v else -1\n",
    "        else:\n",
    "            return -1 if x > v else 1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.init_args(X, y)\n",
    "\n",
    "        for epoch in range(self.clf_num):\n",
    "            best_clf_error, best_v, clf_result = 100000, None, None\n",
    "            # æ ¹æ®ç‰¹å¾ç»´åº¦, é€‰æ‹©è¯¯å·®æœ€å°çš„\n",
    "            for j in range(self.N):\n",
    "                features = self.X[:, j]\n",
    "                # åˆ†ç±»é˜ˆå€¼ï¼Œåˆ†ç±»è¯¯å·®ï¼Œåˆ†ç±»ç»“æœ\n",
    "                v, direct, error, compare_array = self._G(\n",
    "                    features, self.Y, self.weights)\n",
    "\n",
    "                if error < best_clf_error:\n",
    "                    best_clf_error = error\n",
    "                    best_v = v\n",
    "                    final_direct = direct\n",
    "                    clf_result = compare_array\n",
    "                    axis = j\n",
    "\n",
    "                # print('epoch:{}/{} feature:{} error:{} v:{}'.format(epoch, self.clf_num, j, error, best_v))\n",
    "                if best_clf_error == 0:\n",
    "                    break\n",
    "\n",
    "            # è®¡ç®—G(x)ç³»æ•°a\n",
    "            a = self._alpha(best_clf_error)\n",
    "            self.alpha.append(a)\n",
    "            # è®°å½•åˆ†ç±»å™¨\n",
    "            self.clf_sets.append((axis, best_v, final_direct))\n",
    "            # è§„èŒƒåŒ–å› å­\n",
    "            Z = self._Z(self.weights, a, clf_result)\n",
    "            # æƒå€¼æ›´æ–°\n",
    "            self._w(a, clf_result, Z)\n",
    "\n",
    "\n",
    "#             print('classifier:{}/{} error:{:.3f} v:{} direct:{} a:{:.5f}'.format(epoch+1, self.clf_num, error, best_v, final_direct, a))\n",
    "#             print('weight:{}'.format(self.weights))\n",
    "#             print('\\n')\n",
    "\n",
    "    def predict(self, feature):\n",
    "        result = 0.0\n",
    "        for i in range(len(self.clf_sets)):\n",
    "            axis, clf_v, direct = self.clf_sets[i]\n",
    "            f_input = feature[axis]\n",
    "            result += self.alpha[i] * self.G(f_input, clf_v, direct)\n",
    "        # sign\n",
    "        return 1 if result > 0 else -1\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            feature = X_test[i]\n",
    "            if self.predict(feature) == y_test[i]:\n",
    "                right_count += 1\n",
    "\n",
    "        return right_count / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575757575757576"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(10).reshape(10, 1)\n",
    "y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])\n",
    "\n",
    "clf = AdaBoost(n_estimators=3, learning_rate=0.5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "clf = AdaBoost(n_estimators=10, learning_rate=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score:67.576%\n"
     ]
    }
   ],
   "source": [
    "# 100æ¬¡ç»“æœ\n",
    "result = []\n",
    "for i in range(1, 101):\n",
    "    X, y = create_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf = AdaBoost(n_estimators=100, learning_rate=0.2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    r = clf.score(X_test, y_test)\n",
    "    # print('{}/100 scoreï¼š{}'.format(i, r))\n",
    "    result.append(r)\n",
    "\n",
    "print('average score:{:.3f}%'.format(sum(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implements with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "- algorithmï¼šè¿™ä¸ªå‚æ•°åªæœ‰AdaBoostClassifieræœ‰ã€‚ä¸»è¦åŸå› æ˜¯scikit-learnå®ç°äº†ä¸¤ç§Adabooståˆ†ç±»ç®—æ³•ï¼ŒSAMMEå’ŒSAMME.Rã€‚ä¸¤è€…çš„ä¸»è¦åŒºåˆ«æ˜¯å¼±å­¦ä¹ å™¨æƒé‡çš„åº¦é‡ï¼ŒSAMMEä½¿ç”¨äº†å’Œæˆ‘ä»¬çš„åŸç†ç¯‡é‡ŒäºŒå…ƒåˆ†ç±»Adaboostç®—æ³•çš„æ‰©å±•ï¼Œå³ç”¨å¯¹æ ·æœ¬é›†åˆ†ç±»æ•ˆæœä½œä¸ºå¼±å­¦ä¹ å™¨æƒé‡ï¼Œè€ŒSAMME.Rä½¿ç”¨äº†å¯¹æ ·æœ¬é›†åˆ†ç±»çš„é¢„æµ‹æ¦‚ç‡å¤§å°æ¥ä½œä¸ºå¼±å­¦ä¹ å™¨æƒé‡ã€‚ç”±äºSAMME.Rä½¿ç”¨äº†æ¦‚ç‡åº¦é‡çš„è¿ç»­å€¼ï¼Œè¿­ä»£ä¸€èˆ¬æ¯”SAMMEå¿«ï¼Œå› æ­¤AdaBoostClassifierçš„é»˜è®¤ç®—æ³•algorithmçš„å€¼ä¹Ÿæ˜¯SAMME.Rã€‚æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨é»˜è®¤çš„SAMME.Rå°±å¤Ÿäº†ï¼Œä½†æ˜¯è¦æ³¨æ„çš„æ˜¯ä½¿ç”¨äº†SAMME.Rï¼Œ åˆ™å¼±åˆ†ç±»å­¦ä¹ å™¨å‚æ•°base_estimatorå¿…é¡»é™åˆ¶ä½¿ç”¨æ”¯æŒæ¦‚ç‡é¢„æµ‹çš„åˆ†ç±»å™¨ã€‚SAMMEç®—æ³•åˆ™æ²¡æœ‰è¿™ä¸ªé™åˆ¶ã€‚\n",
    "\n",
    "\n",
    "- n_estimatorsï¼š AdaBoostClassifierå’ŒAdaBoostRegressoréƒ½æœ‰ï¼Œå°±æ˜¯æˆ‘ä»¬çš„å¼±å­¦ä¹ å™¨çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œæˆ–è€…è¯´æœ€å¤§çš„å¼±å­¦ä¹ å™¨çš„ä¸ªæ•°ã€‚ä¸€èˆ¬æ¥è¯´n_estimatorså¤ªå°ï¼Œå®¹æ˜“æ¬ æ‹Ÿåˆï¼Œn_estimatorså¤ªå¤§ï¼Œåˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼Œä¸€èˆ¬é€‰æ‹©ä¸€ä¸ªé€‚ä¸­çš„æ•°å€¼ã€‚é»˜è®¤æ˜¯50ã€‚åœ¨å®é™…è°ƒå‚çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸å°†n_estimatorså’Œä¸‹é¢ä»‹ç»çš„å‚æ•°learning_rateä¸€èµ·è€ƒè™‘ã€‚\n",
    "\n",
    "\n",
    "-  learning_rate:  AdaBoostClassifierå’ŒAdaBoostRegressoréƒ½æœ‰ï¼Œå³æ¯ä¸ªå¼±å­¦ä¹ å™¨çš„æƒé‡ç¼©å‡ç³»æ•°Î½\n",
    "\n",
    "\n",
    "- base_estimatorï¼šAdaBoostClassifierå’ŒAdaBoostRegressoréƒ½æœ‰ï¼Œå³æˆ‘ä»¬çš„å¼±åˆ†ç±»å­¦ä¹ å™¨æˆ–è€…å¼±å›å½’å­¦ä¹ å™¨ã€‚ç†è®ºä¸Šå¯ä»¥é€‰æ‹©ä»»ä½•ä¸€ä¸ªåˆ†ç±»æˆ–è€…å›å½’å­¦ä¹ å™¨ï¼Œä¸è¿‡éœ€è¦æ”¯æŒæ ·æœ¬æƒé‡ã€‚æˆ‘ä»¬å¸¸ç”¨çš„ä¸€èˆ¬æ˜¯CARTå†³ç­–æ ‘æˆ–è€…ç¥ç»ç½‘ç»œMLPã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.5,\n",
       "                   n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8787878787878788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
